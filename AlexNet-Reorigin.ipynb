{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import helper as hp\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from KerasLayers.Custom_layers import LRN2D\n",
    "from keras import regularizers\n",
    "\n",
    "import  PIL.Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 Class Problem\n"
     ]
    }
   ],
   "source": [
    "img_dir = './Datasets/101_ObjectCategories/'\n",
    "categories = os.listdir(img_dir)\n",
    "N_CATEGORY = len(categories)\n",
    "print(N_CATEGORY, 'Class Problem')\n",
    "\n",
    "cat_to_ind = dict()\n",
    "for ind, cat in enumerate(categories):\n",
    "    cat_to_ind[cat] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_img, train_label = [], []\n",
    "\n",
    "for category in categories:\n",
    "    files = [ f for f in os.listdir(img_dir + category)]\n",
    "    \n",
    "    for file in files:\n",
    "        filename = img_dir + category + '/' + file\n",
    "        img = load_img(filename)\n",
    "        img = img.resize((227,227))\n",
    "        train_img.append(img)\n",
    "        train_label.append(cat_to_ind[category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_ALL = len(train_img)\n",
    "num_labels = len(np.unique(train_label))\n",
    "\n",
    "x_all = np.empty((N_ALL, 227, 227, 3), np.float32)\n",
    "y_all = np_utils.to_categorical(train_label, num_labels)\n",
    "\n",
    "for i in range(N_ALL):\n",
    "    x_all[i,:,:,:] = train_img[i]\n",
    "\n",
    "# shuffle data\n",
    "from random import shuffle\n",
    "ind_list = [i for i in range(N_ALL)]\n",
    "shuffle(ind_list)\n",
    "x_all = x_all[ind_list, :,:,:]\n",
    "y_all = y_all[ind_list,]\n",
    "\n",
    "\n",
    "del train_img\n",
    "del train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6941 1736\n"
     ]
    }
   ],
   "source": [
    "N_TRAIN = int(np.floor(N_ALL * 0.8))\n",
    "N_TEST = int(N_ALL - N_TRAIN)\n",
    "\n",
    "x_train = x_all[:N_TRAIN, :,:,:]\n",
    "y_train = y_all[:N_TRAIN,]\n",
    "\n",
    "x_test = x_all[N_TRAIN:N_ALL, :,:,:]\n",
    "y_test = y_all[N_TRAIN:N_ALL, ]\n",
    "\n",
    "del x_all\n",
    "del y_all\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## AlexNet Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NB_CLASS = 1         # number of classes\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "ALPHA = 0.0001\n",
    "BETA = 0.75\n",
    "GAMMA = 0.1\n",
    "DROPOUT = 0.5\n",
    "WEIGHT_DECAY = 0.0005\n",
    "LRN2D_norm = True       # whether to use batch normalization\n",
    "DIM_ORDERING = 'tf'\n",
    "\n",
    "def conv2D_lrn2d(x, nb_filter, nb_row, nb_col,\n",
    "                 border_mode='same', subsample=(1, 1),\n",
    "                 activation='relu', LRN2D_norm=True,\n",
    "                 weight_decay=WEIGHT_DECAY, dim_ordering=DIM_ORDERING):\n",
    "    '''\n",
    "        Info:\n",
    "            Function taken from the Inceptionv3.py script keras github\n",
    "            Utility function to apply to a tensor a module Convolution + lrn2d\n",
    "            with optional weight decay (L2 weight regularization).\n",
    "    '''\n",
    "    if weight_decay:\n",
    "        W_regularizer = regularizers.l2(weight_decay)\n",
    "        b_regularizer = regularizers.l2(weight_decay)\n",
    "    else:\n",
    "        W_regularizer = None\n",
    "        b_regularizer = None\n",
    "\n",
    "    x = Convolution2D(nb_filter, nb_row, nb_col,\n",
    "                      subsample=subsample,\n",
    "                      activation=activation,\n",
    "                      border_mode=border_mode,\n",
    "                      W_regularizer=W_regularizer,\n",
    "                      b_regularizer=b_regularizer,\n",
    "                      bias=False)(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    if LRN2D_norm:\n",
    "\n",
    "        x = LRN2D(alpha=ALPHA, beta=BETA)(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home1/shikhar_csa/try/my_proj/local/lib/python3.4/site-packages/ipykernel/__main__.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (11, 11), strides=(1, 1), bias_regularizer=<keras.reg..., use_bias=False, kernel_regularizer=<keras.reg..., padding=\"same\", activation=\"relu\")`\n",
      "/storage/home1/shikhar_csa/try/my_proj/local/lib/python3.4/site-packages/ipykernel/__main__.py:36: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "/storage/home1/shikhar_csa/try/my_proj/local/lib/python3.4/site-packages/ipykernel/__main__.py:41: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "/storage/home1/shikhar_csa/try/my_proj/local/lib/python3.4/site-packages/ipykernel/__main__.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (55, 55), strides=(1, 1), bias_regularizer=<keras.reg..., use_bias=False, kernel_regularizer=<keras.reg..., padding=\"same\", activation=\"relu\")`\n",
      "/storage/home1/shikhar_csa/try/my_proj/local/lib/python3.4/site-packages/ipykernel/__main__.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (27, 27), strides=(1, 1), bias_regularizer=<keras.reg..., use_bias=False, kernel_regularizer=<keras.reg..., padding=\"same\", activation=\"relu\")`\n",
      "/storage/home1/shikhar_csa/try/my_proj/local/lib/python3.4/site-packages/ipykernel/__main__.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (13, 13), strides=(1, 1), bias_regularizer=<keras.reg..., use_bias=False, kernel_regularizer=<keras.reg..., padding=\"same\", activation=\"relu\")`\n",
      "/storage/home1/shikhar_csa/try/my_proj/local/lib/python3.4/site-packages/ipykernel/__main__.py:44: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=101, activation=\"softmax\")`\n",
      "/storage/home1/shikhar_csa/try/my_proj/local/lib/python3.4/site-packages/ipykernel/__main__.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "INP_SHAPE = (227, 227, 3)  # 3 - Number of RGB Colours\n",
    "img_input = Input(shape=INP_SHAPE)\n",
    "CONCAT_AXIS = 3\n",
    "\n",
    "# Channel 1 - Convolution Net Layer 1\n",
    "x = conv2D_lrn2d(img_input, 3, 11, 11, subsample=(1, 1))\n",
    "x = MaxPooling2D(strides=(4, 4), pool_size=(4, 4))(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "\n",
    "# Channel 1 - Convolution Net Layer 2\n",
    "x = conv2D_lrn2d(x, 48, 55, 55, subsample=(1, 1))\n",
    "x = MaxPooling2D(strides=(2, 2), pool_size=(2, 2))(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "\n",
    "# Channel 1 - Convolution Net Layer 3\n",
    "x = conv2D_lrn2d(x, 128, 27, 27, subsample=(1, 1))\n",
    "x = MaxPooling2D(strides=(2, 2), pool_size=(2, 2))(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "\n",
    "# Channel 1 - Convolution Net Layer 4\n",
    "x = conv2D_lrn2d(x, 192, 13, 13, subsample=(1, 1))\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "\n",
    "# Channel 1 - Convolution Net Layer 5\n",
    "x = conv2D_lrn2d(x, 192, 13, 13, subsample=(1, 1))\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "\n",
    "# Channel 1 - Cov Net Layer 6\n",
    "x = conv2D_lrn2d(x, 128, 27, 27, subsample=(1, 1))\n",
    "x = MaxPooling2D(\n",
    "    strides=(2, 2), pool_size=(2, 2))(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "\n",
    "# Channel 1 - Cov Net Layer 7\n",
    "x = Flatten()(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(DROPOUT)(x)\n",
    "\n",
    "# Channel 1 - Cov Net Layer 8\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(DROPOUT)(x)\n",
    "\n",
    "# Final Channel - Cov Net 9\n",
    "model_output = Dense(output_dim=num_labels, activation='softmax')(x)\n",
    "\n",
    "# return x, img_input, CONCAT_AXIS, INP_SHAPE, DIM_ORDERING\n",
    "model = Model(input=img_input, output = model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "pl.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "class Histories(keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "        self.val_acc = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.acc.append(logs['acc'])\n",
    "        self.loss.append(logs['loss'])\n",
    "        self.val_acc.append(logs['val_acc'])\n",
    "        self.val_loss.append(logs['val_loss'])\n",
    "        \n",
    "        pl.hold(True)\n",
    "        plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "        pl.plot(self.acc, 'r')\n",
    "        pl.plot(self.loss, 'b')\n",
    "        pl.plot(self.val_acc, 'g')\n",
    "        pl.plot(self.val_loss, 'k')\n",
    "        pl.legend(['Train acc','Train loss','Valid acc', 'Valid loss'], loc=2)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(pl.gcf())\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6941 samples, validate on 1736 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.rmsprop(), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "histories = Histories()\n",
    "res = model.fit(x_train, y_train,\n",
    "          batch_size = 10,\n",
    "          epochs=100, \n",
    "          validation_data = (x_test, y_test), verbose=2, callbacks=[histories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Train Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
